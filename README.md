Final Thoughts
After completing a project, it is helpful to reflect on and highlight important aspects of the entire process to help solidify our learning.

It's critically important to understand the data we're working with. Keeping the dataset description close at hand and referring to it often can help avoid confusion! Faulty assumptions early on can easily lead us to confusing results later on.

As part of the Exploratory Data Analysis phase, always ensure the consistency and validity of the data. It's vital to identify any outliers, incorrect data, or any other error that can compromise the integrity of the data.

Exercise good judgement when selecting the columns to train the model while making the necessary transformations (like a correct encoding) to ensure the model interprets the data correctly.

Take all the time you need during the Data Cleaning phase to ensure there are no incorrect observations that could potentially foul the model during training.

When creating the Decision Tree algorithm, under no circumstances should we skip the evaluation phase! It can often provide us with clues about which hyperparameters to add or change when optimizing the model later on.

It's good practice to double check our Trees with the Random Forest technique.

Finally, if we're going to explain our findings to an audience, it pays to come prepared. While it's true that Decision Trees are easier to explain than other machine learning algorithms, it is still a machine learning algorithm and non-technical audiences will naturally be aprehensive!

You may have noticed that we made sure to comply with all these points throughout this project. This explains why we were able to create a highly accurate Decision Tree. While the steps that involved the scikit-learn library were of vital importance, we should never underestimate the value of all the preparation we did prior.

![download](https://github.com/user-attachments/assets/d8112e1e-0959-403b-b50b-0ffd21ee9517)
